{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d17921a",
   "metadata": {},
   "source": [
    "# **Experiment 1: Value Model Measurements**\n",
    "\n",
    "1. **Workload Latencies**: Measure the response times of the system.\n",
    "2. **Latency Prediction Q-Errors**: Evaluate the accuracy of the system's latency prediction model by calculating Q-Errors, which quantify the deviation between predicted and actual latencies.\n",
    "3. **Inference Times**: Analyze the time taken for the system to process and generate predictions, providing insights into its computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53862a",
   "metadata": {},
   "source": [
    "### **Hardware Used**\n",
    "\n",
    "| **System**                                      | **CPU**                                       | **RAM**                                      | **Storage**                                   | **GPU**                                          | **Platform**                                     |\n",
    "|-------------------------------------------------|-----------------------------------------------|----------------------------------------------|-----------------------------------------------|-------------------------------------------------|-------------------------------------------------|\n",
    "| **BAO**                                         | Intel Xeon Gold 6230                         | 15GB (VM) + 256GB (CPU)                      | Not specified                                 | Tesla T4 GPU                                     | Google Cloud Platform (N1-4 VM)                 |\n",
    "| **LOGER**                                       | 2Ã— Intel Xeon Gold                           | 256GB                                        | Not specified                                 | NVIDIA RTX 3090                                  | Physical Server                                 |\n",
    "| **BALSA**                                       | Microsoft Azure VMs (8 cores)                | 64GB                                         | SSD                                           | NVIDIA Tesla M60 GPU                             | Microsoft Azure                                 |\n",
    "| **FASTgres**                                    | Intel Xeon Gold 6216 (12 cores)              | 92GB                                         | 1.8 TiB storage                               | Not specified                                    | Physical Server                                 |\n",
    "| **train-server (Hosts PostgreSQL)**             | QEMU Virtual CPU version 2.5                 | 110GB                                        | 2.0 TiB SSD                                   | None                                            | Physical Server                                 |\n",
    "| **train-gpu-server (Hosts the optimizers)**     | Intel(R) Xeon(R) Gold 5318Y                  | 377GB                                        | 1.4 TiB SSD                                   | NVIDIA RTX A6000                                  | Physical Server                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9b67a",
   "metadata": {},
   "source": [
    "### **PostgreSQL Configurations**\n",
    "\n",
    "| **PostgreSQL Config Parameter**  | **Description** | **Default Values** | **JOB** | **Bao** | **Balsa** | **LOGER** | **Our Framework** |\n",
    "|----------------------------------|----------------|------------------|-------------|-------------|-----------------------|-------------|----------------|\n",
    "| **Join Order** |  |  |  |  |  |  |  |\n",
    "| geqo_threshold | Sets the threshold for Genetic Query Optimizer (GEQO) to be used | 12 | 18 |  |  | 2 or 1,024 |  |\n",
    "| geqo | Enables or disables GEQO, which helps optimize complex queries | on |  |  | off | off | off |\n",
    "| **Working Memory** |  |  |  |  |  |  |  |\n",
    "| work_mem | Memory allocated for each query operation (e.g., sorting, hashing) | 4 MB | 2 GB |  | 4 GB | | 4 GB |\n",
    "| shared_buffers | Memory used for PostgreSQL's buffer cache to reduce disk I/O | 128 MB | 4 GB | 4 GB | 32 GB | 64 GB | 32 GB |\n",
    "| temp_buffers | Memory allocated for temporary tables during a session | 8 MB |  |  | 32 GB |  | 32 GB |\n",
    "| effective_cache_size | Estimated memory available for caching disk pages | 4 GB | 32 GB |  |  |  | 64 GB |\n",
    "| **Parallelization** |  |  |  |  |  |  |  |\n",
    "| max_parallel_workers | Maximum number of parallel workers allowed | 8 |  |  |  | 1 | 8 |\n",
    "| max_parallel_workers_per_gather | Maximum parallel workers per `Gather` node in a query plan | 8 |  |  |  | 1 | 8 |\n",
    "| max_worker_processes | Maximum background worker processes allowed | 2 |  |  | 8 |  | 8 |\n",
    "| **Scan Types** |  |  |  |  |  |  |  |\n",
    "| enable_bitmapscan | Enables bitmap scans for efficient index-based retrieval | on |  | | off |  | on |\n",
    "| enable_tidscan | Enables TID scans, which use tuple IDs for direct row lookups | on |  |  | off |  | on |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd11b27",
   "metadata": {},
   "source": [
    "## **Benchmarks Used**\n",
    "\n",
    "### **1. JOB and its Variants**\n",
    "\n",
    "#### **Join Order Benchmark (Default)**\n",
    "\n",
    "- Evaluates the efficiency of database query optimizers, focusing on join order optimization and cardinality estimation accuracy.\n",
    "- 21 Tables, 6 Columns per Table on Average, 3.6 GB in size, 113 Queries in total, 8 average Joins per query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78707a",
   "metadata": {},
   "source": [
    "## **2. TPC-H and Its Variants**  \n",
    "\n",
    "### **TPC-H-NO-NESTED-QUERIES**  \n",
    "- Uses **templates 3, 5, 12, and 14** for training and **template 10** for testing, with **10 queries per template**.  \n",
    "- Excludes queries containing **nested subqueries** in either the **FROM** or **WHERE** clause.  \n",
    "- Templates **7, 8, and 13** are excluded due to their reliance on these nested structures, which **LOGER** and **FASTgres** cannot process.  \n",
    "- **Example of Banned Queries:**  \n",
    "\n",
    "  **1. Nested FROM Clause (Disallowed)**  \n",
    "  ```sql\n",
    "  SELECT o_orderkey, revenue\n",
    "  FROM (\n",
    "      SELECT l_orderkey AS o_orderkey, SUM(l_extendedprice) AS revenue\n",
    "      FROM lineitem\n",
    "      GROUP BY l_orderkey\n",
    "  ) AS subquery\n",
    "  WHERE revenue > 100000;\n",
    "  ```\n",
    "  - This query is excluded because it **uses a subquery in the FROM clause (nested FROM)**.  \n",
    "\n",
    "  **2. Nested WHERE Clause (Disallowed)**  \n",
    "  ```sql\n",
    "  SELECT l_orderkey\n",
    "  FROM lineitem\n",
    "  WHERE l_extendedprice > (\n",
    "      SELECT AVG(l_extendedprice)\n",
    "      FROM lineitem\n",
    "  );\n",
    "  ```\n",
    "  - This query is excluded because it **contains a subquery in the WHERE clause**.  \n",
    "\n",
    "- **Compatible with:**  \n",
    "  - BAO  \n",
    "  - Balsa  \n",
    "  - FASTgres  \n",
    "  - LOGER  \n",
    "\n",
    "### **3. TPC-DS**  \n",
    "\n",
    "### **3.1 TPC-DS-SIMPLE** (originates from *LOGER*)\n",
    "- Only queries in SPJ Format\n",
    "- Uses **15 templates for training** and **5 templates for testing**, ensuring that all tables in the testing workload appear in the training workload.  \n",
    "- Generates **3 queries per template** for both training and testing.  \n",
    "- **Training Templates:** 3, 7, 12, 20, 26, 37, 42, 43, 50, 55, 62, 84, 91, 96, 99  \n",
    "- **Testing Templates:** 18, 27, 52, 82, 98  \n",
    "- **Compatible with:**\n",
    "  - BAO\n",
    "  - LOGER  \n",
    "  - FASTgres (WIP)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ec9b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "OPTIMIZERS = ['BAO', 'LOGER', 'LERO', 'NEO']\n",
    "# ==============================================================================\n",
    "# 1. DATA COLLECTION\n",
    "# ==============================================================================\n",
    "\n",
    "def parse_checkpoint_name(name):\n",
    "    epoch_match = re.search(r\"epoch-?(\\d+)\", name)\n",
    "    queries_match = re.search(r\"queries-?(\\d+)\", name)\n",
    "    loss_match = re.search(r\"loss-?([-\\d.e]+)\", name)\n",
    "    epoch = int(epoch_match.group(1)) if epoch_match else -1\n",
    "    queries = int(queries_match.group(1)) if queries_match else -1\n",
    "    loss = float(loss_match.group(1)) if loss_match else -1.0\n",
    "    return epoch, queries, loss\n",
    "\n",
    "def discover_checkpoints(models_base_dir, optimizer_name):\n",
    "    \"\"\"\n",
    "    Discovers trained model checkpoints for a given optimizer.\n",
    "    Keeps .pt, .pkl, and valid checkpoint directories.\n",
    "    Excludes metadata, baselines, and final_model files.\n",
    "    \"\"\"\n",
    "    checkpoint_list = []\n",
    "    optimizer_path = Path(models_base_dir) / optimizer_name.upper()\n",
    "    subdirs = [\"epoch_checkpoints\", \"query_checkpoints\", \"loss_checkpoints\"]\n",
    "\n",
    "    unique_names = set()\n",
    "    allowed_extensions = {\".pt\", \".pkl\"}  # valid checkpoint files\n",
    "\n",
    "    exclude_patterns = (\n",
    "        \"_metadata.json\",\n",
    "        \"_metadata.txt\",\n",
    "        \"_baseline.pkl\",\n",
    "    )\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        full_subdir_path = optimizer_path / subdir\n",
    "        if not full_subdir_path.is_dir():\n",
    "            continue\n",
    "\n",
    "        for item_path in full_subdir_path.iterdir():\n",
    "            # --- case 1: valid file checkpoint ---\n",
    "            if item_path.is_file():\n",
    "                if item_path.suffix not in allowed_extensions:\n",
    "                    continue\n",
    "                if any(str(item_path).endswith(pattern) for pattern in exclude_patterns):\n",
    "                    continue\n",
    "                if item_path.stem.startswith(\"final_model\"):\n",
    "                    continue\n",
    "                base_name = item_path.stem\n",
    "\n",
    "            # --- case 2: valid directory checkpoint ---\n",
    "            elif item_path.is_dir():\n",
    "                # skip final_model dirs or metadata dirs\n",
    "                if item_path.name.startswith(\"final_model\"):\n",
    "                    continue\n",
    "                # heuristic: treat any directory without extension as checkpoint\n",
    "                base_name = item_path.name\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # avoid duplicates\n",
    "            if base_name not in unique_names:\n",
    "                # print(f\"Discovered checkpoint: {base_name}\")\n",
    "                # print(f\"  Path: {item_path}\")\n",
    "                unique_names.add(base_name)\n",
    "                checkpoint_list.append({\n",
    "                    \"name\": base_name,\n",
    "                    \"type\": subdir,\n",
    "                    \"path\": str(item_path)\n",
    "                })\n",
    "    return checkpoint_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24e50ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_execution_time(plan_json):\n",
    "    try:\n",
    "        if isinstance(plan_json, list) and isinstance(plan_json[-1], dict) and 'Execution Time' in plan_json[-1]:\n",
    "            return plan_json[-1].get('Execution Time', 0.0)\n",
    "        if isinstance(plan_json, list) and 'Execution Time' in plan_json[0]:\n",
    "            return plan_json[0]['Execution Time']\n",
    "        if isinstance(plan_json, list) and isinstance(plan_json[0], list) and 'Execution Time' in plan_json[-1][0][0]:\n",
    "            return plan_json[0][0][0]['Execution Time']\n",
    "        if isinstance(plan_json, dict) and 'Execution Time' in plan_json:\n",
    "            return plan_json.get('Execution Time', 0.0)\n",
    "    except (IndexError, KeyError, TypeError): pass\n",
    "    return 0.0\n",
    "\n",
    "def extract_planning_time(plan_json):\n",
    "    try:\n",
    "        if isinstance(plan_json, list) and isinstance(plan_json[-1], dict) and 'Planning Time' in plan_json[-1]:\n",
    "            return plan_json[-1].get('Planning Time', 0.0)\n",
    "        if isinstance(plan_json, list) and 'Planning Time' in plan_json[0]:\n",
    "            return plan_json[0]['Planning Time']\n",
    "        if isinstance(plan_json, list) and isinstance(plan_json[0], list) and 'Planning Time' in plan_json[-1][0][0]:\n",
    "            return plan_json[0][0][0]['Planning Time']\n",
    "        if isinstance(plan_json, dict) and 'Planning Time' in plan_json:\n",
    "            return plan_json.get('Planning Time', 0.0)\n",
    "    except (IndexError, KeyError, TypeError): pass\n",
    "    return 0.0\n",
    "\n",
    "def build_trajectory_df_from_files(discovered_checkpoints, results_base_dir, optimizer_name):\n",
    "    rows = []\n",
    "    for checkpoint in tqdm(discovered_checkpoints, desc=f\"Processing {optimizer_name} Checkpoints\"):\n",
    "        name, type_dir = checkpoint['name'], checkpoint['type']\n",
    "        pattern = Path(results_base_dir) / \"*\" / optimizer_name.upper() / type_dir / name / \"**\" / \"*_plan.json\"\n",
    "        plan_files = glob.glob(str(pattern), recursive=True)\n",
    "        if not plan_files: continue\n",
    "        total_lat_ms, q_errors = 0, []\n",
    "        for plan_path in plan_files:\n",
    "            pred_lat_ms, exec_time_ms = np.nan, 0\n",
    "            try:\n",
    "                with open(plan_path, 'r') as f: plan_data = json.load(f)\n",
    "                exec_time_ms = extract_execution_time(plan_data)\n",
    "                planning_time_ms = extract_planning_time(plan_data)\n",
    "                if exec_time_ms > 0: total_lat_ms += exec_time_ms\n",
    "                if planning_time_ms > 0: total_lat_ms += planning_time_ms\n",
    "                if optimizer_name.upper() == 'BAO':\n",
    "                    if isinstance(plan_data, list) and len(plan_data) > 0 and 'Bao' in plan_data[0]:\n",
    "                        pred_lat_ms = plan_data[0]['Bao'].get('Bao prediction', np.nan)\n",
    "                else:\n",
    "                    metrics_path = plan_path.replace('_plan.json', '_metrics.json')\n",
    "                    if os.path.exists(metrics_path):\n",
    "                        # print(f\"Loading metrics from {metrics_path}\")\n",
    "                        with open(metrics_path, 'r') as f: metrics_data = json.load(f)\n",
    "                        pred_lat_ms = metrics_data.get('predicted_latency_ms', np.nan)\n",
    "                if exec_time_ms > 0 and not np.isnan(pred_lat_ms) and pred_lat_ms > 0:\n",
    "                    if optimizer_name.upper() == 'NEO':\n",
    "                        pred_lat_ms *= 10\n",
    "                    q_errors.append(max(pred_lat_ms / exec_time_ms, exec_time_ms / pred_lat_ms))\n",
    "            except Exception: continue\n",
    "        if total_lat_ms == 0: continue\n",
    "        rows.append({\n",
    "            \"optimizer\": optimizer_name, \"checkpoint_type\": type_dir.replace(\"_checkpoints\", \"\"),\n",
    "            **dict(zip([\"epoch\", \"queries_seen\", \"model_loss\"], parse_checkpoint_name(name))),\n",
    "            \"cumulative_latency_s\": total_lat_ms / 1000.0, \"avg_q_error\": np.mean(q_errors) if q_errors else np.nan\n",
    "        })\n",
    "    return pd.DataFrame(rows)   \n",
    "\n",
    "def get_postgres_baseline(results_base_dir):\n",
    "    # search_pattern = Path(results_base_dir) / \"POSTGRES\" / \"**\" / \"*_plan.json\"\n",
    "    search_pattern = Path(results_base_dir) / \"**\" / \"classic_qep.json\"\n",
    "    print(f\"Searching for Postgres baseline plans in {search_pattern}\")\n",
    "    plan_files = glob.glob(str(search_pattern), recursive=True)\n",
    "    if not plan_files: return None\n",
    "    total_latency_ms = sum(extract_execution_time(json.load(open(p, 'r'))) for p in plan_files)\n",
    "    return total_latency_ms / 1000.0 if total_latency_ms > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09629f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimizer_grid(df_long, optimizer_name, output_dir, baseline_latency=None, smooth_window=5):\n",
    "    \"\"\"\n",
    "    Generates a master grid plot for a SINGLE optimizer based on the provided data.\n",
    "    The structure of the grid is automatically determined by the metrics and policies in df_long.\n",
    "    \"\"\"\n",
    "    print(f\"\\nGenerating custom grid plot for {optimizer_name}...\")\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "    # Determine grid structure from the data provided\n",
    "    row_order = sorted(df_long[\"Metric\"].unique())\n",
    "    col_order = sorted(df_long[\"Training Policy\"].unique())\n",
    "\n",
    "    # --- Setup plot ---\n",
    "    palette = sns.color_palette(\"Purples\", 6)\n",
    "    g = sns.relplot(\n",
    "        data=df_long, x=\"Progress Value\", y=\"Metric Value\",\n",
    "        row=\"Metric\", col=\"Training Policy\",\n",
    "        row_order=row_order, col_order=col_order,\n",
    "        kind=\"line\", marker=\"s\", dashes=False, color=palette[4], label=\"Raw\",\n",
    "        facet_kws={'sharey': False, 'sharex': False, 'margin_titles': True},\n",
    "        height=4, aspect=1.5\n",
    "    )\n",
    "\n",
    "    # --- Customize each subplot ---\n",
    "    for (metric, policy), ax in g.axes_dict.items():\n",
    "        subset = df_long[(df_long[\"Metric\"] == metric) & (df_long[\"Training Policy\"] == policy)]\n",
    "        if subset.empty:\n",
    "            continue\n",
    "\n",
    "        subset = subset.sort_values(\"Progress Value\").reset_index(drop=True)\n",
    "\n",
    "        # Smoothed line\n",
    "        smooth_y = subset[\"Metric Value\"].rolling(window=smooth_window, min_periods=1, center=True).mean()\n",
    "        ax.plot(subset[\"Progress Value\"], smooth_y,\n",
    "                color=palette[2], lw=2.5, alpha=0.6, label=\"Smoothed\", marker=\"D\")\n",
    "\n",
    "        # Grid and axis customization\n",
    "        ax.grid(which=\"major\", axis=\"both\", linestyle=\":\", alpha=0.5)\n",
    "        ax.set_yscale('log')\n",
    "        if metric == 'Workload Latency (s)' and baseline_latency is not None and optimizer_name.upper() != \"NEO\":\n",
    "            ax.axhline(baseline_latency, ls='--', color='red', lw=1.5, label='PostgreSQL Baseline')\n",
    "        if policy == \"Model Loss\":\n",
    "            ax.invert_xaxis()\n",
    "\n",
    "    # --- Final Touches ---\n",
    "    g.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "    g.fig.suptitle(f'Performance Trajectory for {optimizer_name.upper()}', fontsize=16, y=1.05)\n",
    "    \n",
    "    handles, labels = g.axes.flatten()[0].get_legend_handles_labels()\n",
    "    unique_labels = dict(zip(labels, handles))\n",
    "    g.fig.legend(unique_labels.values(), unique_labels.keys(),\n",
    "                 loc=\"upper center\", ncol=3, frameon=True, bbox_to_anchor=(0.5, 0.98))\n",
    "\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "\n",
    "    filename = f\"trajectory_grid_{optimizer_name}.pdf\"\n",
    "    plt.savefig(Path(output_dir) / filename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved plot: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef355a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.lines as mlines\n",
    "\n",
    "def plot_combined_latency_vs_queries(df_long, output_dir, baseline_latency=None, smooth_window=5):\n",
    "    \"\"\"\n",
    "    Creates a 1x4 grid of plots, each showing workload latency vs. queries seen\n",
    "    for one optimizer, styled similarly to the main optimizer grids and with\n",
    "    non-shared y-axes.\n",
    "    \"\"\"\n",
    "    print(\"\\nGenerating 1x4 combined plot for Latency vs. Queries Seen...\")\n",
    "    df_subset = df_long[\n",
    "        (df_long['Metric'] == 'Workload Latency (s)') &\n",
    "        (df_long['Training Policy'] == 'Queries Seen')\n",
    "    ].copy()\n",
    "\n",
    "    if df_subset.empty:\n",
    "        print(\"No data found for the combined latency vs. queries plot. Skipping.\")\n",
    "        return\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    # Use a consistent color palette, like in the template function\n",
    "    palette = sns.color_palette(\"Purples\", 6)\n",
    "    \n",
    "    # Define a consistent order for the columns\n",
    "    col_order = sorted(df_long[\"Training Policy\"].unique())\n",
    "    row_order = sorted(df_long[\"Metric\"].unique())\n",
    "\n",
    "    # --- Use relplot to create the FacetGrid ---\n",
    "    # `col='optimizer'` creates the 1x4 layout.\n",
    "    # `facet_kws={'sharey': False}` is the key for independent y-axes.\n",
    "    g = sns.relplot(\n",
    "        data=df_subset,\n",
    "        x='Progress Value',\n",
    "        y='Metric Value',\n",
    "        col=\"Training Policy\",\n",
    "        row=\"Metric\",\n",
    "        row_order=row_order,\n",
    "        col_order=col_order,\n",
    "        kind='line',\n",
    "        marker='s',\n",
    "        color=palette[4], # Use a fixed color for the 'Raw' line\n",
    "        height=4,\n",
    "        aspect=1.2,\n",
    "        facet_kws={'sharey': False, 'sharex': False}, # Independent axes\n",
    "        legend=False # We will create a custom legend\n",
    "    )\n",
    "\n",
    "    # --- Customize each subplot (ax) ---\n",
    "    for optimizer_name, ax in g.axes_dict.items():\n",
    "        # Get the specific data for this subplot\n",
    "        subset = df_subset[df_subset['optimizer'] == optimizer_name]\n",
    "        if subset.empty:\n",
    "            continue\n",
    "        \n",
    "        subset = subset.sort_values(\"Progress Value\").reset_index(drop=True)\n",
    "\n",
    "        # Add the smoothed line, just like in the template\n",
    "        smooth_y = subset[\"Metric Value\"].rolling(window=smooth_window, min_periods=1, center=True).mean()\n",
    "        ax.plot(subset[\"Progress Value\"], smooth_y,\n",
    "                color=palette[2], lw=2.5, alpha=0.7, marker=\"D\")\n",
    "\n",
    "        # Apply log scale, grid, and baseline to each subplot\n",
    "        ax.set_yscale('log')\n",
    "        ax.grid(which=\"major\", axis=\"both\", linestyle=\":\", alpha=0.7)\n",
    "        if baseline_latency:\n",
    "            # NEO doesn't get the baseline in other plots, maintain consistency\n",
    "            if optimizer_name.upper() != \"NEO\":\n",
    "                ax.axhline(baseline_latency, ls='--', color='red', lw=2)\n",
    "\n",
    "    # --- Add figure-level titles, labels, and legend ---\n",
    "    g.fig.suptitle('Workload Latency vs. Queries Seen Policy', fontsize=18, y=1.08)\n",
    "    g.set_titles(col_template=\"{col_name}\", size=14)\n",
    "    g.set_axis_labels(\"Queries Seen (Progress)\", \"Workload Latency (s)\")\n",
    "\n",
    "    # Manually create a single, clean legend for the entire figure\n",
    "    raw_handle = mlines.Line2D([], [], color=palette[4], marker='s', linestyle='-', label='Raw')\n",
    "    smooth_handle = mlines.Line2D([], [], color=palette[2], marker='D', linestyle='-', label='Smoothed')\n",
    "    \n",
    "    legend_handles = [raw_handle, smooth_handle]\n",
    "    if baseline_latency:\n",
    "        legend_handles.append(mlines.Line2D([], [], color='red', ls='--', lw=2, label='PostgreSQL Baseline'))\n",
    "\n",
    "    g.fig.legend(handles=legend_handles, loc='upper center', ncol=3,\n",
    "                 bbox_to_anchor=(0.5, 1.0), frameon=True)\n",
    "\n",
    "    plt.subplots_adjust(top=0.85) # Adjust layout to prevent title overlap\n",
    "\n",
    "    filename = \"combined_latency_vs_queries_grid.pdf\"\n",
    "    plt.savefig(Path(output_dir) / filename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved plot: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c08945a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Data for: BAO ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing BAO Checkpoints: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 29.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Data for: LOGER ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LOGER Checkpoints: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 50.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Data for: LERO ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LERO Checkpoints: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:00<00:00, 50.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Data for: NEO ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing NEO Checkpoints: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:00<00:00, 671.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for Postgres baseline plans in /data/hdd1/users/kmparmp/Learned-Optimizers-Benchmarking-Suite/experiments/experiment3/test/**/classic_qep.json\n",
      "\n",
      "PostgreSQL Baseline Latency (for reference): 178.98s\n",
      "\n",
      "Reshaping data for master plot...\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "MODELS_BASE_DIR = '/data/hdd1/users/kmparmp/Learned-Optimizers-Benchmarking-Suite/models/experiment3'\n",
    "RESULTS_BASE_DIR = '/data/hdd1/users/kmparmp/Learned-Optimizers-Benchmarking-Suite/experiments/experiment3/test/'\n",
    "OUTPUT_DIR = '/data/hdd1/users/kmparmp/Learned-Optimizers-Benchmarking-Suite/experiments/experiment3/plots'\n",
    "OPTIMIZERS = ['BAO', 'LOGER', 'LERO', 'NEO']\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Step 1: Consolidate data ---\n",
    "all_trajectories = []\n",
    "for optimizer in OPTIMIZERS:\n",
    "    print(f\"\\n--- Processing Data for: {optimizer} ---\")\n",
    "    discovered = discover_checkpoints(MODELS_BASE_DIR, optimizer)\n",
    "    if not discovered:\n",
    "        print(f\"No checkpoints found for {optimizer}. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    df = build_trajectory_df_from_files(discovered, RESULTS_BASE_DIR, optimizer)\n",
    "    if not df.empty:\n",
    "        all_trajectories.append(df)\n",
    "\n",
    "if not all_trajectories:\n",
    "    print(\"No data collected for any optimizer. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "master_df = pd.concat(all_trajectories, ignore_index=True)\n",
    "pg_baseline_latency = get_postgres_baseline(RESULTS_BASE_DIR)\n",
    "# MODIFICATION: We still calculate the baseline, just don't plot it for now.\n",
    "# This makes it easy to re-enable later.\n",
    "if pg_baseline_latency:\n",
    "    print(f\"\\nPostgreSQL Baseline Latency (for reference): {pg_baseline_latency:.2f}s\")\n",
    "else:\n",
    "    print(\"\\nPostgreSQL baseline results not found.\")\n",
    "\n",
    "\n",
    "# --- Step 2: Reshape data from wide to long format for FacetGrid plotting ---\n",
    "print(\"\\nReshaping data for master plot...\")\n",
    "dfs_to_concat = []\n",
    "policy_map = {\n",
    "    'epoch': ('Epochs', 'epoch'),\n",
    "    'query': ('Queries Seen', 'queries_seen'),\n",
    "    'loss': ('Model Loss', 'model_loss')\n",
    "}\n",
    "for policy_short, (policy_long, col_name) in policy_map.items():\n",
    "    df_policy = master_df[master_df['checkpoint_type'] == policy_short].copy()\n",
    "    # Filter out placeholder values like -1\n",
    "    df_policy = df_policy[df_policy[col_name] >= 0] \n",
    "    \n",
    "    df_lat = df_policy[['optimizer', col_name, 'cumulative_latency_s']].rename(columns={\n",
    "        col_name: 'Progress Value', 'cumulative_latency_s': 'Metric Value'\n",
    "    })\n",
    "    df_lat['Training Policy'] = policy_long\n",
    "    df_lat['Metric'] = 'Workload Latency (s)'\n",
    "    \n",
    "    df_qerr = df_policy[['optimizer', col_name, 'avg_q_error']].rename(columns={\n",
    "        col_name: 'Progress Value', 'avg_q_error': 'Metric Value'\n",
    "    })\n",
    "    df_qerr['Training Policy'] = policy_long\n",
    "    df_qerr['Metric'] = 'Average Q-Error'\n",
    "    \n",
    "    dfs_to_concat.extend([df_lat, df_qerr])\n",
    "\n",
    "long_df = pd.concat(dfs_to_concat, ignore_index=True).dropna()\n",
    "long_df = long_df.sort_values(by=['optimizer', 'Training Policy', 'Progress Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48069b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what to keep for each optimizer\n",
    "plot_config = {\n",
    "    \"GLOBAL\": [\n",
    "        (\"Workload Latency (s)\", \"Queries Seen\"),\n",
    "    ],\n",
    "    \"NEO\": [\n",
    "        (\"Workload Latency (s)\", \"Epochs\"),\n",
    "        (\"Workload Latency (s)\", \"Model Loss\"),\n",
    "    ],\n",
    "    \"BAO\": [\n",
    "        (\"Workload Latency (s)\", \"Epochs\"),\n",
    "        (\"Average Q-Error\", \"Epochs\"),\n",
    "        (\"Workload Latency (s)\", \"Model Loss\"),\n",
    "    ],\n",
    "    \"LOGER\": [\n",
    "        (\"Workload Latency (s)\", \"Epochs\"),\n",
    "        (\"Average Q-Error\", \"Epochs\"),\n",
    "        (\"Workload Latency (s)\", \"Queries Seen\"),\n",
    "    ],\n",
    "    \"LERO\": [\n",
    "        (\"Workload Latency (s)\", \"Epochs\"),\n",
    "        (\"Workload Latency (s)\", \"Queries Seen\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "def filter_long_df(df, optimizer, keep_pairs):\n",
    "    \"\"\"Filter df for one optimizer based on (Metric, Training Policy) pairs.\"\"\"\n",
    "    mask_optimizer = df[\"optimizer\"] == optimizer\n",
    "    mask_pairs = df.apply(lambda row: (row[\"Metric\"], row[\"Training Policy\"]) in keep_pairs, axis=1)\n",
    "    return df[mask_optimizer & mask_pairs].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating custom grid plot for NEO...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Metric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/data/hdd1/users/kmparmp/miniconda3/envs/jobgen/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Metric'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m neo_df \u001b[38;5;241m=\u001b[39m filter_long_df(long_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEO\u001b[39m\u001b[38;5;124m\"\u001b[39m, plot_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEO\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplot_optimizer_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneo_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNEO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpg_baseline_latency\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Example: plot BAO\u001b[39;00m\n\u001b[1;32m      5\u001b[0m bao_df \u001b[38;5;241m=\u001b[39m filter_long_df(long_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBAO\u001b[39m\u001b[38;5;124m\"\u001b[39m, plot_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBAO\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[50], line 15\u001b[0m, in \u001b[0;36mplot_optimizer_grid\u001b[0;34m(df_long, optimizer_name, output_dir, baseline_latency, smooth_window)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# --- Setup plot ---\u001b[39;00m\n\u001b[1;32m     14\u001b[0m palette \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mcolor_palette(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPurples\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_long\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProgress Value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMetric Value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMetric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining Policy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdashes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpalette\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRaw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfacet_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msharey\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msharex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmargin_titles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# --- Customize each subplot ---\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (metric, policy), ax \u001b[38;5;129;01min\u001b[39;00m g\u001b[38;5;241m.\u001b[39maxes_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/data/hdd1/users/kmparmp/miniconda3/envs/jobgen/lib/python3.9/site-packages/seaborn/relational.py:829\u001b[0m, in \u001b[0;36mrelplot\u001b[0;34m(data, x, y, hue, size, style, units, weights, row, col, col_wrap, row_order, col_order, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, dashes, style_order, legend, kind, height, aspect, facet_kws, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;66;03m# Set up the FacetGrid object\u001b[39;00m\n\u001b[1;32m    828\u001b[0m facet_kws \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m facet_kws \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m facet_kws\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 829\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mFacetGrid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgrid_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_wrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_wrap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfacet_kws\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Draw the plot\u001b[39;00m\n\u001b[1;32m    838\u001b[0m g\u001b[38;5;241m.\u001b[39mmap_dataframe(func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplot_kws)\n",
      "File \u001b[0;32m/data/hdd1/users/kmparmp/miniconda3/envs/jobgen/lib/python3.9/site-packages/seaborn/axisgrid.py:397\u001b[0m, in \u001b[0;36mFacetGrid.__init__\u001b[0;34m(self, data, row, col, hue, col_wrap, sharex, sharey, height, aspect, palette, row_order, col_order, hue_order, hue_kws, dropna, legend_out, despine, margin_titles, xlim, ylim, subplot_kws, gridspec_kws)\u001b[0m\n\u001b[1;32m    395\u001b[0m     row_names \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 397\u001b[0m     row_names \u001b[38;5;241m=\u001b[39m categorical_order(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m, row_order)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     col_names \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/data/hdd1/users/kmparmp/miniconda3/envs/jobgen/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/data/hdd1/users/kmparmp/miniconda3/envs/jobgen/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Metric'"
     ]
    }
   ],
   "source": [
    "# neo_df = filter_long_df(long_df, \"NEO\", plot_config[\"NEO\"])\n",
    "# plot_optimizer_grid(neo_df, \"NEO\", OUTPUT_DIR, pg_baseline_latency)\n",
    "\n",
    "# Example: plot BAO\n",
    "bao_df = filter_long_df(long_df, \"BAO\", plot_config[\"BAO\"])\n",
    "plot_optimizer_grid(bao_df, \"BAO\", OUTPUT_DIR, pg_baseline_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer_name = \"BAO\"\n",
    "# df_single_optimizer = long_df[long_df['optimizer'] == optimizer_name]\n",
    "# if optimizer_name == \"LERO\":\n",
    "#     df_single_optimizer = df_single_optimizer[df_single_optimizer['Training Policy'] != \"Model Loss\"]\n",
    "# if optimizer_name == \"BAO\":\n",
    "#     long_df.loc[(long_df['optimizer'] == 'BAO') & (long_df['Training Policy'] == 'Model Loss'), 'Progress Value'] *= 1000\n",
    "# if not df_single_optimizer.empty:\n",
    "#     plot_optimizer_grid(\n",
    "#         df_single_optimizer,\n",
    "#         optimizer_name,\n",
    "#         OUTPUT_DIR,\n",
    "#         pg_baseline_latency\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055b80a",
   "metadata": {},
   "source": [
    "**BAO**\n",
    "\n",
    "- Epoch-based Training:\n",
    "  - Some signs of overfitting at the end of the curve with the latency regressing\n",
    "  - The moment the workload latency hits its lowest point, the Q-Error has actually hit a local maximum, suggesting that Q-Error is not the only metric that should be accounted for when tracking learning progress, but rather a component of the tracking\n",
    "- Queries seen policy actually demonstrates many spikes\n",
    "- Loss-based training showed the most linear trajectory out of every counterpart, seems to be the best metric for BAO's training module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6aa638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer_name = \"LOGER\"\n",
    "# df_single_optimizer = long_df[long_df['optimizer'] == optimizer_name]\n",
    "# if optimizer_name == \"LERO\":\n",
    "#     df_single_optimizer = df_single_optimizer[df_single_optimizer['Training Policy'] != \"Model Loss\"]    \n",
    "# if not df_single_optimizer.empty:\n",
    "#     plot_optimizer_grid(\n",
    "#         df_single_optimizer,\n",
    "#         optimizer_name,\n",
    "#         OUTPUT_DIR,\n",
    "#         pg_baseline_latency\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e79b5e",
   "metadata": {},
   "source": [
    "**LOGER**\n",
    "\n",
    "- More susceptible to wide margin regressions during training, across all 3 training paradigms\n",
    "- Here average Q-Error seems to be a lot better at indicating training progress, as latency local minima map with q-error local minima, and also vice verse about the maxima\n",
    "- This probably happens because of the Tree-LSTM & GT architecture that structures the embedding space in a better way\n",
    "- (We still need to find a module that works best for LOGER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d29728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer_name = \"NEO\"\n",
    "# df_single_optimizer = long_df[long_df['optimizer'] == optimizer_name]\n",
    "# if optimizer_name == \"LERO\":\n",
    "#     df_single_optimizer = df_single_optimizer[df_single_optimizer['Training Policy'] != \"Model Loss\"]\n",
    "# if not df_single_optimizer.empty:\n",
    "#     plot_optimizer_grid(\n",
    "#         df_single_optimizer,\n",
    "#         optimizer_name,\n",
    "#         OUTPUT_DIR,\n",
    "#         pg_baseline_latency\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a19d0c",
   "metadata": {},
   "source": [
    "**NEO**\n",
    "\n",
    "- Loss-related checkpoints are very minute (only 15) because the network never went below the 0.93 training loss mark\n",
    "- So many spikes cause the optimizer does not converge\n",
    "- The fact that the Model does not converge in terms of training loss explains every behavior we have seen from NEO so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9991ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer_name = \"LERO\"\n",
    "# df_single_optimizer = long_df[long_df['optimizer'] == optimizer_name]\n",
    "# if optimizer_name == \"LERO\":\n",
    "#     df_single_optimizer = df_single_optimizer[df_single_optimizer['Training Policy'] != \"Model Loss\"]    \n",
    "# if not df_single_optimizer.empty:\n",
    "#     plot_optimizer_grid(\n",
    "#         df_single_optimizer,\n",
    "#         optimizer_name,\n",
    "#         OUTPUT_DIR,\n",
    "#         pg_baseline_latency\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
